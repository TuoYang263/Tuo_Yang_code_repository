{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOH0MvhIhMoYMfN7xZcTFOI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"U88sF6HYg3x3"},"source":["from keras.models import Model\r\n","#a series common-used network layers has been defined inside the core, including full-connected layers and activtation layers\r\n","from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout \r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","\r\n","def get_unet(n_ch,patch_height,patch_width):\r\n","    inputs = Input(shape=(n_ch,patch_height,patch_width))\r\n","    # data_format: string, one of \"channels_first\" or \"channels_last\", which indicates channel positions of images\r\n","    # take the 128 by 128 RGB image as the example, \"channels_first\" should organize data as (3,128,128), while\r\n","    # \"channels_last\" should organize data as (128,128,3)\r\n","    # default values of this parameter is the value set inside ~/.keras/keras.json\r\n","    # if it has not been set up yet, it's channels_last\r\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\r\n","    conv1 = Dropout(0.2)(conv1)\r\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\r\n","    pool1 = MaxPooling2D((2, 2))(conv1)\r\n","    #\r\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\r\n","    conv2 = Dropout(0.2)(conv2)\r\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\r\n","    pool2 = MaxPooling2D((2, 2))(conv2)\r\n","    #\r\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\r\n","    conv3 = Dropout(0.2)(conv3)\r\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\r\n","\r\n","    up1 = UpSampling2D(size=(2, 2))(conv3)\r\n","    up1 = concatenate([conv2,up1],axis=1)\r\n","    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\r\n","    conv4 = Dropout(0.2)(conv4)\r\n","    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\r\n","    #\r\n","    up2 = UpSampling2D(size=(2, 2))(conv4)\r\n","    up2 = concatenate([conv1,up2], axis=1)\r\n","    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\r\n","    conv5 = Dropout(0.2)(conv5)\r\n","    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\r\n","    #\r\n","    #the function of 1 cross 1 convolution 1. realize interaction and information melting\r\n","    #between different channels 2. proceeding dimensions increasing and decreasing of convolutional channels\r\n","    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\r\n","    # currently, the output shape is (batchsize,2,patch_height*patch_width)\r\n","    conv6 = core.Reshape((2,patch_height*patch_width))(conv6)\r\n","    # currently, the shape of output is (Npatch,patch_height*patch_width,2),  which the dimension of output is\r\n","    # (Npatch,2304,2)\r\n","    conv6 = core.Permute((2,1))(conv6)\r\n","    ############\r\n","    conv7 = core.Activation('softmax')(conv6)\r\n","    model = Model(inputs=inputs, outputs=conv7)\r\n","    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\r\n","    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\r\n","    return model\r\n"],"execution_count":null,"outputs":[]}]}